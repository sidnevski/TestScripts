{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17e6dc-6b78-40fe-9a20-881cbdf29863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score, roc_auc_score, accuracy_score, mean_squared_error,\n",
    "                             confusion_matrix, precision_recall_curve, roc_curve, brier_score_loss)\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e17d2-7902-45c5-9f95-4e6733c205d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "columns_drop = {\n",
    "    \"Facebook_data\": None,\n",
    "    \"Features_TestSet\": None,\n",
    "    \"House_Price_Adv_Regression\": ['Id'],\n",
    "    \"Instant_Liking\": None,\n",
    "    \"Insurance\": None,\n",
    "    \"Isolet\": None,\n",
    "    \"new_data_trans\": None,\n",
    "    \"OnlineNewsPopularity\": None,\n",
    "    \"ParkinsonData\": ['subject.'],\n",
    "    \"Sberbank_Russian_Housing_Market\": ['id'],\n",
    "    \"slice_localization_data\": None,\n",
    "    \"Telecom_data\": ['Phone.Number'],\n",
    "    \"yearMSD_new\": None,\n",
    "    \"arrhythmia\": None,\n",
    "    \"Big_mart_sales\": ['Item_Identifier', 'Outlet_Identifier', 'Outlet_Establishment_Year'],\n",
    "    \"blogData\": None,\n",
    "    \"communities\": ['x4', 'x1'],\n",
    "    \"dengue_features\": ['year', 'weekofyear', 'week_start_date'],\n",
    "    \"ECG0_p02\": None,\n",
    "    \"ENERGY_DATA_COMPLETE\": None\n",
    "}\n",
    "\n",
    "fill_na = {\n",
    "    \"Facebook_data\": False,\n",
    "    \"Features_TestSet\": False,\n",
    "    \"House_Price_Adv_Regression\": False,\n",
    "    \"Instant_Liking\": False,\n",
    "    \"Insurance\": False,\n",
    "    \"Isolet\": False,\n",
    "    \"new_data_trans\": False,\n",
    "    \"OnlineNewsPopularity\": False,\n",
    "    \"ParkinsonData\": False,\n",
    "    \"Sberbank_Russian_Housing_Market\": False,\n",
    "    \"slice_localization_data\": False,\n",
    "    \"Telecom_data\": False,\n",
    "    \"yearMSD_new\": False,\n",
    "    \"arrhythmia\": False,\n",
    "    \"Big_mart_sales\": True,\n",
    "    \"blogData\": False,\n",
    "    \"communities\": False,\n",
    "    \"dengue_features\": False,\n",
    "    \"ECG0_p02\": False,\n",
    "    \"ENERGY_DATA_COMPLETE\": False\n",
    "}\n",
    "\n",
    "fill_na_column = {\n",
    "    \"Facebook_data\": [],\n",
    "    \"Features_TestSet\": [],\n",
    "    \"House_Price_Adv_Regression\": [],\n",
    "    \"Instant_Liking\": [],\n",
    "    \"Insurance\": [],\n",
    "    \"Isolet\": [],\n",
    "    \"new_data_trans\": [],\n",
    "    \"OnlineNewsPopularity\": [],\n",
    "    \"ParkinsonData\": [],\n",
    "    \"Sberbank_Russian_Housing_Market\": [],\n",
    "    \"slice_localization_data\": [],\n",
    "    \"Telecom_data\": [],\n",
    "    \"yearMSD_new\": [],\n",
    "    \"arrhythmia\": [],\n",
    "    \"Big_mart_sales\": ['Outlet_Size'],\n",
    "    \"blogData\": [],\n",
    "    \"communities\": [],\n",
    "    \"dengue_features\": [],\n",
    "    \"ECG0_p02\": [],\n",
    "    \"ENERGY_DATA_COMPLETE\": [],\n",
    "}\n",
    "\n",
    "def process_dataset(df_train, df_test, columns_drop, fill_na, fill_na_columns):    \n",
    "    df_total = pd.concat([df_train, df_test], axis=0)\n",
    "    tar = df_total.iloc[:, -1]\n",
    "    df_total = df_total.iloc[:, :-1]\n",
    "    \n",
    "    if fill_na:\n",
    "        for column in fill_na_columns:\n",
    "            df_total[column].fillna(\"NOT_PRESENT\", inplace=True)\n",
    "    \n",
    "    if columns_drop:\n",
    "        df_total = df_total.drop(columns_drop, axis='columns')\n",
    "    \n",
    "    cat = df_total.select_dtypes(include=['object']).columns.to_list()\n",
    "    df_total = pd.get_dummies(df_total, cat)\n",
    "    \n",
    "    df_total = pd.concat([df_total, tar], axis=1)\n",
    "    df_train = df_total.iloc[:df_train.shape[0],:]\n",
    "    df_test = df_total.iloc[df_train.shape[0]:,:]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "data_dir = \"/home/asim/ssriva59/setup-stuff/gateway_and_dataset\"\n",
    "datasets = [\n",
    "    # \"Facebook_data\",\n",
    "    # \"Features_TestSet\",\n",
    "    # \"House_Price_Adv_Regression\",\n",
    "    # \"Instant_Liking\",\n",
    "    # \"Insurance\",\n",
    "    \"Isolet\",\n",
    "    # \"new_data_trans\",\n",
    "    # \"OnlineNewsPopularity\",\n",
    "    # \"ParkinsonData\",\n",
    "    # \"Sberbank_Russian_Housing_Market\",\n",
    "    # \"slice_localization_data\",\n",
    "    # \"Telecom_data\",\n",
    "    # \"yearMSD_new\",\n",
    "    # \"arrhythmia\",\n",
    "    # \"Big_mart_sales\",\n",
    "    # \"blogData\",\n",
    "    # \"communities\",\n",
    "    # \"dengue_features\",\n",
    "    # \"ECG0_p02\",\n",
    "    # \"ENERGY_DATA_COMPLETE\"\n",
    "]\n",
    "\n",
    "# Fill missing for Instant_Liking\n",
    "\n",
    "seeds = [1, 50, 100, 150, 200, 250, 300, 350, 400, 450]\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        csv_path_train = os.path.join(data_dir, dataset, \"Train\", dataset + '_Train_seed' + str(seed) + '.csv')\n",
    "        df_train = pd.read_csv(csv_path_train)\n",
    "        \n",
    "        csv_path_test = os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '.csv')\n",
    "        df_test = pd.read_csv(csv_path_test)\n",
    "        \n",
    "        df_train, df_test = process_dataset(df_train, df_test, columns_drop[dataset], fill_na[dataset], fill_na_column[dataset])\n",
    "        df_train.to_csv(os.path.join(data_dir, dataset, \"Train\", dataset + '_Train_seed' + str(seed) + '_modified.csv'), index=False)\n",
    "        df_test.to_csv(os.path.join(data_dir, dataset, \"Test\", dataset + '_Test_seed' + str(seed) + '_modified.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334232e-5da7-4b3f-8060-185c439b8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and validation sets\n",
    "\n",
    "data_dir = \"/home/asim/ssriva59/setup-stuff/gateway_and_dataset\"\n",
    "datasets = [\n",
    "    # \"Facebook_data\",\n",
    "    # \"Features_TestSet\",\n",
    "    # \"House_Price_Adv_Regression\",\n",
    "    # \"Instant_Liking\",\n",
    "    # \"Insurance\",\n",
    "    \"Isolet\",\n",
    "    # \"new_data_trans\",\n",
    "    # \"OnlineNewsPopularity\",\n",
    "    # \"ParkinsonData\",\n",
    "    # \"Sberbank_Russian_Housing_Market\",\n",
    "    # \"slice_localization_data\",\n",
    "    # \"Telecom_data\",\n",
    "    # \"yearMSD_new\",\n",
    "    # \"arrhythmia\",\n",
    "    # \"Big_mart_sales\",\n",
    "    # \"blogData\",\n",
    "    # \"communities\",\n",
    "    # \"dengue_features\",\n",
    "    # \"ECG0_p02\",\n",
    "    # \"ENERGY_DATA_COMPLETE\"\n",
    "]\n",
    "\n",
    "train_split = 0.8\n",
    "\n",
    "seeds = [1, 50, 100, 150, 200, 250, 300, 350, 400, 450]\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    df = pd.DataFrame()\n",
    "    print(dataset)\n",
    "    for seed in tqdm(seeds):\n",
    "        data = []\n",
    "        # print(os.path.join(data_dir, dataset, \"Train\", dataset + '_Train_seed' + str(seed) + '_modified.csv'))\n",
    "        for each_line in open(os.path.join(data_dir, dataset, \"Train\", dataset + '_Train_seed' + str(seed) + '_modified.csv')):\n",
    "            each_line = each_line.strip().split(',')\n",
    "            data.append(each_line)\n",
    "            \n",
    "        headers = data.pop(0)\n",
    "        \n",
    "        random.shuffle(data)\n",
    "        \n",
    "        train_datapoints = int(train_split * len(data))\n",
    "        train_set = [headers] + data[:train_datapoints]\n",
    "        validation_set = [headers] + data[train_datapoints:]\n",
    "        \n",
    "        train_set_df = pd.DataFrame(train_set)\n",
    "        train_set_df.to_csv(os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_train.csv'), index=False, header=False)\n",
    "        \n",
    "        validation_set_df = pd.DataFrame(validation_set)\n",
    "        validation_set_df.to_csv(os.path.join(data_dir, dataset, \"Train\", dataset + '_seed_' + str(seed) + '_validation.csv'), index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
